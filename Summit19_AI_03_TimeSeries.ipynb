{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/insight.svg\" style=\"width: 300px\"><br>\n",
    "<font color='#544640'>\n",
    "<center><i>Engineering Summit 2019</i></center>\n",
    "<center><i>Denver, Colorado</i></center></font><br>\n",
    "<center><i><font color='#544640' size='1'>Author: Victor Aranda</font></i></center></font>\n",
    "<center><i><font color='#B81590' size='1'>victor.aranda@insight.com</font></i></center></font>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"#D21087\">Time Series Analysis</font>\n",
    "\n",
    "<font color='#544640'>Time series analysis is a set of mathematical techniques for analyzing a sequence, or sequences, of data points to determine the characteristics of any underlying ***processes*** driving the changes in the values of the data points over time and model those changes to reproduce the original series from white noise. Phew!\n",
    "\n",
    "In other words, stuff changes over time and it pays to be able to figure out how it will change in the future. Time series analysis is used as a tool for forecasting, primarily. Can you think of a few areas where this may be applicable or valuable?<br><br>\n",
    "\n",
    "* Locale-specific tides versus lunar orbit and Earth rotation\n",
    "* Financial markets analysis\n",
    "* Compute/storage/network/etc utilization over time\n",
    "* Electronic signals analysis, electronic warfare\n",
    "\n",
    "There is a great deal of math behind all of this but we will not get into the weeds. Instead, we will learn the concepts behind some very fancy words which represent very powerful mathematic analytical tools. \n",
    "\n",
    "* AutoCorrelation and Partial AutoCorrelation (ACF & PACF)\n",
    "* AutoRegressive Integrated Moving Average (ARIMA)\n",
    "* AutoRegressive Conditional Heteroskedasticity (ARCH)\n",
    "* Vector Error Correction Model (VECM)\n",
    "\n",
    "In performing the analysis to forecast, we must understand some mathematical characteristics within the data. These characteristics can also be used to perform ***cluster*** and ***classify*** series. Where would that be useful?\n",
    "\n",
    "* Radio telescope, stellar spectral data, classifying stars\n",
    "* Sonar, classifying oceanic animals, vehicles, submarines\n",
    "\n",
    "\n",
    "\n",
    "##### <font color=\"#D21087\">Further Reading:</font>\n",
    "    \n",
    "https://en.wikipedia.org/wiki/Time_series\n",
    "\n",
    "https://en.wikipedia.org/wiki/Stationary_process\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><font color=\"#B81590\">$$\\large-\\infty-$$</font><br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# environment setup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.api import VAR\n",
    "from statsmodels.tsa.stattools import coint, grangercausalitytests\n",
    "from statsmodels.tsa.stattools import adfuller, acf, pacf\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from statsmodels.tsa.vector_ar.var_model import VARResults\n",
    "from statsmodels.tsa.vector_ar.vecm import select_coint_rank, select_order, VECM\n",
    "from statsmodels.tsa.arima_model import ARIMA, ARIMAResults\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><font color=\"#B81590\">$$\\large-\\infty-$$</font><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"#D21087\">Modeling a Time Series</font>\n",
    "\n",
    "<font color='#544640'>Here we're going to model a time series (a set of data points along a period of time). \n",
    "    \n",
    "First we have to identify any ***auto-correlation*** or ***moving-average*** behavior. Then we'll effectively remove either term, if they exist, from the data according to the type we've uncovered (generally via a number of ***lags***)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a helper function\n",
    "\n",
    "def myADF(t, r = False):\n",
    "    # t is a series of values, intended to be a time series\n",
    "    # r is a boolean which determines if the p value is returned \n",
    "    #    INSTEAD OF displaying output\n",
    "    # from Brownlee Ch 15.7\n",
    "    result = adfuller(t)    \n",
    "    if not r:\n",
    "        # print results\n",
    "        print('ADF Statistic:\\t%f' % result[0])\n",
    "        print('p-value:\\t%f' % result[1])\n",
    "        if result[1] > 0.05:\n",
    "            print('\\t\\tSeries is non-stationary.')\n",
    "        elif result[1] <= 0.05:\n",
    "            print('\\t\\t\\tSeries is stationary.')\n",
    "        print('Critical Values:')\n",
    "        for key, value in result[4].items():\n",
    "            print('\\t\\t%s:\\t%.3f' % (key, value))\n",
    "    if r:\n",
    "        return result[1] # return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "champ_df = pd.read_csv('./data/champagne.csv', parse_dates=True, index_col=0, squeeze=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "champ_df.plot(kind='line',figsize=[12,6])\n",
    "plt.title(\"Champagne Consumption\")\n",
    "plt.xlabel('Months\\n1964-1972')\n",
    "plt.ylabel('Bottles')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='#544640'>What behavior do you see in the data? Anything obvious?\n",
    "    \n",
    "We'll do a Dickey-Fuller test to see whether the series is ***stationary***.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myADF(champ_df, r = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='#544640'>Let's decompose this series into different components - its trend and its seasonality. Trend is a ***moving-average*** and seasonality is ***auto-correlation***.\n",
    "\n",
    "Note that this is a somewhat 'rough', or naive, sort of decomposition (it is not as rigorous as heavy-duty methods).</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# we want to set the frequency of our analysis to 12 months based on a good hunch\n",
    "result = seasonal_decompose(champ_df, model='additive', freq = 12)\n",
    "result.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='#544640'>Clearly wine consumption is going up - and we know roughly how much without having to worry about other noise in the data.\n",
    "\n",
    "Similarly we can clearly discern a very strong periodicity in the data, and we can isolate that periodicity from the trend and noise to analyze the yearly pattern. Surprise! People love drinking wine around New Year's Eve and the holidays.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src='./img/leo.gif'></center><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='#544640'>What kinds of trending or seasonality do you see in your jobs?</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><font color=\"#B81590\">$$\\large-\\infty-$$</font><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"#D21087\">Modeling a Time Series</font>\n",
    "\n",
    "<font color='#544640'>Here we will model and forecast the data in `robberies.csv` based on an ARIMA(2,1,1) model. We'll hold back 25% of the data and only work with the remaining 75% to develop the model, and compare our forecast to the 25% after we're finished.\n",
    "\n",
    "While we're talking about ARIMA modeling,<br><br>\n",
    "    \n",
    "$$\\large \\left(1-\\sum _{i=1}^{p}\\phi _{i}L^{i}\\right)(1-L)^{d}X_{t}=\\delta +\\left(1+\\sum _{i=1}^{q}\\theta _{i}L^{i}\\right)\\varepsilon _{t}$$<br><br>\n",
    "\n",
    "<center><img src='./img/math.jpg' width='300'></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_df = pd.read_csv('./data/robberies.csv', parse_dates=True, index_col=0)\n",
    "rob1_df = orig_df.copy()\n",
    "rob1_df.plot(kind='line',figsize=[14,6])\n",
    "plt.title('Robberies over time, 1966 - 1976')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = rob1_df.Robberies\n",
    "y.index = pd.DatetimeIndex(y.index.values, freq = y.index.inferred_freq)\n",
    "n = len(y)\n",
    "\n",
    "ratio = 0.75\n",
    "\n",
    "train = y.iloc[0:(int(round(ratio*n)))]\n",
    "test = y.iloc[int(round(ratio*n)):n]\n",
    "\n",
    "history = [x for x in train]\n",
    "\n",
    "p = 2\n",
    "d = 1\n",
    "q = 1\n",
    "\n",
    "model = ARIMA(history, order=(p,d,q))\n",
    "model_fit = model.fit(disp=0)\n",
    "\n",
    "# prediction time series\n",
    "p_ts = pd.Series(model_fit.forecast(steps = len(test))[0], index = pd.DatetimeIndex(test.index.values, freq = test.index.inferred_freq))\n",
    "\n",
    "limits = pd.DataFrame(model_fit.forecast(steps=len(test))[2])\n",
    "\n",
    "# lower limit time series\n",
    "ll_ts = pd.Series(limits[0])\n",
    "ll_ts.index = pd.DatetimeIndex(test.index.values, freq = test.index.inferred_freq)\n",
    "\n",
    "# upper limit time series\n",
    "ul_ts = pd.Series(limits[1])\n",
    "ul_ts.index = pd.DatetimeIndex(test.index.values, freq = test.index.inferred_freq)\n",
    "\n",
    "# calculate intervals\n",
    "interval_ts = ul_ts - ll_ts\n",
    "\n",
    "# create a subset for zooming in\n",
    "train_subset = train.iloc[int((.9*len(train))):len(train)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "plt.figure(1,figsize=(14,6))\n",
    "\n",
    "plt.subplot(311)\n",
    "plt.plot(train,label='Training Data')\n",
    "plt.fill_between(train.index, train, 0, color = '#1f77b4', alpha=.2)\n",
    "plt.plot(test,label='Testing Data', color = 'gray', linestyle = '--')\n",
    "plt.plot(p_ts,label='Predictions', color = 'green')\n",
    "plt.title('ARIMA(2,2,1) Dynamic Forecast')\n",
    "plt.legend()\n",
    "plt.axhline(y=0, color='gray', linestyle=':')\n",
    "\n",
    "# zoom in\n",
    "plt.subplot(312)\n",
    "plt.subplots_adjust(top=1,bottom=-1)\n",
    "plt.plot(train_subset,label='Training Data')\n",
    "plt.plot(test,label='Testing Data', color = 'darkgray', linestyle = '--')\n",
    "plt.plot(ul_ts, color = 'orange',label='Upper Limit')\n",
    "plt.plot(ll_ts, color = 'orange',label='Lower Limit')\n",
    "plt.plot(p_ts,label='Predictions', color = 'green')\n",
    "plt.fill_between(p_ts.index, ul_ts, ll_ts, color = 'orange', alpha = 0.1, label='Prediction Interval')\n",
    "plt.title('ARIMA(2,2,1) Dynamic Forecast & Prediction Interval')\n",
    "plt.legend()\n",
    "\n",
    "# prediction interval magnitude\n",
    "plt.subplot(313)\n",
    "\n",
    "# include this subset to align plots\n",
    "# adjust magnitude by .5 (or whatever) to get plot to \n",
    "# look right (in proportion to interval data)\n",
    "plt.plot(train_subset*.5, color ='white')\n",
    "plt.plot(interval_ts, label='Interval', color = 'red')\n",
    "plt.fill_between(p_ts.index, interval_ts, 0, color = 'red', alpha=.1)\n",
    "plt.title('Prediction Interval Magnitude')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><font color=\"#B81590\">$$\\large-\\infty-$$</font><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"#D21087\">Predicting Time Series</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading in the data\n",
    "x_df = pd.read_csv('./data/X.csv', index_col=0, names=['val'], header=0)\n",
    "y_df = pd.read_csv('./data/Y.csv', index_col=0, names=['val'], header=0)\n",
    "z_df = pd.read_csv('./data/Z.csv', index_col=0, names=['val'], header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the data and observe\n",
    "\n",
    "plt.figure(1, figsize=(14, 8))\n",
    "plt.subplots_adjust(top=1, bottom=-1)\n",
    "\n",
    "plt.subplot(411)\n",
    "plt.plot(x_df.index, x_df.val, color='#d62728')\n",
    "plt.title('X')\n",
    "\n",
    "plt.subplot(412)\n",
    "plt.plot(y_df.index, y_df.val, color='#9467bd')\n",
    "plt.title('Y')\n",
    "\n",
    "plt.subplot(413)\n",
    "plt.plot(z_df.index, z_df.val, color='#8c564b')\n",
    "plt.title('Z')\n",
    "\n",
    "plt.subplot(414)\n",
    "plt.plot(x_df.index, x_df.val, label='Series X', color='#d62728')\n",
    "plt.plot(y_df.index, y_df.val, label='Series Y', color='#9467bd')\n",
    "plt.plot(z_df.index, z_df.val, label='Series Z', color='#8c564b')\n",
    "plt.title('Series: X, Y, and Z')\n",
    "plt.xlabel('Series Index')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge2_df = pd.DataFrame()\n",
    "merge2_df['X'] = x_df.values.T[0]\n",
    "merge2_df['Y'] = y_df.values.T[0]\n",
    "merge2_df['Z'] = z_df.values.T[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge2_df.index = pd.DatetimeIndex(merge2_df.index.values)\n",
    "merge2_df.index.freq = merge2_df.index.inferred_freq\n",
    "# merge2_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = VAR(merge2_df)\n",
    "lag_order = model2.select_order(20)\n",
    "# print(lag_order.summary())\n",
    "# Best VAR lag order is p=2 based on Akaike Information Criterion (AIC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results2 = model2.fit(2)\n",
    "# print(results2.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_variables = 3\n",
    "n_lags = 2\n",
    "n_roots = n_variables * n_lags\n",
    "\n",
    "VAR_results2 = VARResults.roots(results2)\n",
    "\n",
    "# print('Roots:')\n",
    "# for i in range(n_roots):\n",
    "#     print('  ' + str(round(VAR_results2[i],3)))\n",
    "\n",
    "# print('\\nModuli:')\n",
    "# for i in range(n_roots):\n",
    "#     print('  ' + str(round(np.absolute(VAR_results2[i]),3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='#544640'>We can tell that the model we have built around these time series is not ***stationary*** (that is somewhat obvious from the plot). We can also determine that the series are not ***cointegrated***.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lag_order2 = select_order(data=merge2_df, maxlags=10, deterministic='nc')\n",
    "#print(lag_order2.summary())\n",
    "#print()\n",
    "#print('AIC lag order = ', lag_order2.aic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_test2 = select_coint_rank(merge2_df, 0, 1, method='trace', signif=0.05)\n",
    "#print(rank_test2)\n",
    "#print()\n",
    "#print('Rank = ' + str(rank_test2.rank))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='#544640'>We can create a VECM model for this data given what we know about it. The VECM model can predict what the series will look like a few steps ahead, based on our analysis of the time series.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = VECM(\n",
    "    merge2_df,\n",
    "    deterministic='nc',\n",
    "    k_ar_diff=lag_order2.aic,\n",
    "    coint_rank=rank_test2.rank)\n",
    "\n",
    "vecm_res = model2.fit()\n",
    "# print(vecm_res.summary())\n",
    "\n",
    "# print(vecm_res.alpha)\n",
    "# print(vecm_res.beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict 10 steps ahead\n",
    "vecm_res.predict(steps=10, alpha=.05)\n",
    "\n",
    "# for text, values in zip(('forecast','lower','upper'), vecm_res.predict(steps=10, alpha=.05)):\n",
    "#     print(text+' : ', values, sep='\\n')\n",
    "\n",
    "vecm_res.plot_forecast(steps=10, plot_conf_int=True, n_last_obs=100)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='#544640'>A bit closer now...</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vecm_res.plot_forecast(steps=10, n_last_obs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><font color=\"#B81590\">$$\\large-\\infty-$$</font><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"#D21087\">Sun Spots</font>\n",
    "\n",
    "> Sunspots are temporary phenomena on the Sun's photosphere that appear as spots darker than the surrounding areas. They are regions of reduced surface temperature caused by concentrations of magnetic field flux that inhibit convection. Sunspots usually appear in pairs of opposite magnetic polarity. Their number varies according to the approximately 11-year solar cycle.\n",
    "\n",
    "https://en.wikipedia.org/wiki/Sunspot<br><br>\n",
    "\n",
    "\n",
    "<center><img src='./img/sun.gif'></center>\n",
    "\n",
    "<font color='#544640'>Astronomers have been studying the sunspot cycle since at least 800 BC. Starting in the mid 1700s, detailed record-keeping eventually produced this data set (1749-1983) of the number of sunspots in each month of the year.\n",
    "    \n",
    "Based on the Auto-Correlation Function (ACF) of the `sunspots.csv` dataset, what is the sunspot cycle to the nearest month? Let's find out.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sunspots = pd.read_csv('./data/sunspots.csv', parse_dates=True, index_col=0)\n",
    "sunspots.plot(kind='line',figsize=[14,6])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_acf(sunspots,lags=200)\n",
    "plt.axvline(x=12*11, color='red', linestyle='--', ) # estimated 11 year cycle\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='#544640'>We note that the first peak of the ACF's curve is a bit shy of the estimated 11-year (132-month) cycle. To find the value where the ACF peaks, we will do the following:</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's consider just the number of lags around the auto-correlation peak\n",
    "#   100 - 150 lags\n",
    "# find the max position of that portion of the ACF\n",
    "# add 100 (because we removed 100 when 'zooming in')\n",
    "period_months = acf(sunspots,nlags=200)[100:150].argmax() + 100\n",
    "\n",
    "print('The sunspot period appears to be',round(period_months/12,2),'years.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><font color=\"#B81590\">$$\\large-\\infty-$$</font><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='#544640'>Putting it all together, hopefully you can enjoy the wit and humor of these authors' when they titled their paper:</font><br><br>\n",
    "\n",
    "<center><img src='./img/multiple_coint_ec.png' width=600></center>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
